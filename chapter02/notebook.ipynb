{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. OpenAI の チャット API の基礎\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. 入出力の長さの制限や料金に影響する「トークン」\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トークン\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tiktoken==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "text = \"ChatGPT\"\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = encoding.encode(text)\n",
    "for token in tokens:\n",
    "    print(encoding.decode([token]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer と tiktoken の紹介\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "text = \"LLMを使ってクールなものを作るのは簡単だが、プロダクションで使えるものを作るのは非常に難しい。\"\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = encoding.encode(text)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Chat Completions API を試す環境の準備\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI の API キーの準備\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Chat Completions API のハンズオン\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI のライブラリ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【注意】既知のエラーについて\n",
    "\n",
    "openai パッケージが依存する httpx のアップデートにより、`openai==1.40.6` を使用する箇所で `TypeError: Client.__init__() got an unexpected keyword argument 'proxies'` というエラーが発生するようになりました。\n",
    "\n",
    "このエラーは、`!pip install httpx==0.27.2` のように、httpx の特定バージョンをインストールすることで回避することができます。\n",
    "\n",
    "なお、Google Colab で一度上記のエラーに遭遇したあとで `!pip install httpx==0.27.2` のようにパッケージをインストールし直した場合、以下のどちらかの操作を実施する必要があります。\n",
    "\n",
    "- Google Colab の「ランタイム」から「セッションを再起動する」を実行する\n",
    "- 「ランタイムを接続解除して削除」を実行してパッケージのインストールからやり直す\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install httpx==0.27.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Completions API の呼び出し\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "response = client.converse(\n",
    "    modelId=\"apac.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    system=[{\"text\": \"You are a helpful assistant.\"}],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": \"こんにちは！私はジョンと言います！\"}],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 会話履歴を踏まえた応答を得る\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.converse(\n",
    "    modelId=\"apac.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    system=[{\"text\": \"You are a helpful assistant.\"}],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": \"こんにちは！私はジョンと言います！\"}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [{\"text\": \"こんにちは、ジョンさん！お会いできて嬉しいです。今日はどんなことをお話ししましょうか？\"}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": \"私の名前が分かりますか？\"}],\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ストリーミングで応答を得る\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.converse_stream(\n",
    "    modelId=\"apac.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    system=[{\"text\": \"You are a helpful assistant.\"}],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": \"こんにちは！私はジョンと言います！\"}],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "for chunk in response[\"stream\"]:\n",
    "    if \"contentBlockDelta\" in chunk:\n",
    "        text = chunk[\"contentBlockDelta\"][\"delta\"][\"text\"]\n",
    "        print(text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON モード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "response = client.converse(\n",
    "    modelId=\"apac.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    system=[{\"text\": '人物一覧を次のJSON形式で出力してください。\\n{\"people\": [\"aaa\", \"bbb\"]}'}],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": \"昔々あるところにおじいさんとおばあさんがいました\"}],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision（画像入力）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from openai import OpenAI\n",
    "\n",
    "# client = OpenAI()\n",
    "\n",
    "import boto3\n",
    "import urllib.request\n",
    "import base64\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "image_url = \"https://raw.githubusercontent.com/yoshidashingo/langchain-book/main/assets/cover.jpg\"\n",
    "\n",
    "with urllib.request.urlopen(image_url) as response:\n",
    "    image_data = response.read()\n",
    "\n",
    "response = client.converse(\n",
    "    modelId=\"apac.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"text\": \"Image1: \"},\n",
    "                {\"image\": {\"format\": \"png\", \"source\": {\"bytes\": image_data}}},\n",
    "                {\"text\": \"画像を説明してください。\"},\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### （コラム）Completions API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "response = client.converse(\n",
    "    modelId=\"apac.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    system=[{\"text\": \"You are a helpful assistant.\"}],\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"text\": \"こんにちは！私はジョンと言います！\"}],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Function calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function calling のサンプルコード\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    if \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Tokyo\", \"temperature\": \"10\", \"unit\": unit})\n",
    "    elif \"san francisco\" in location.lower():\n",
    "        return json.dumps(\n",
    "            {\"location\": \"San Francisco\", \"temperature\": \"72\", \"unit\": unit}\n",
    "        )\n",
    "    elif \"paris\" in location.lower():\n",
    "        return json.dumps({\"location\": \"Paris\", \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = {\n",
    "    \"tools\": [\n",
    "        {\n",
    "            \"toolSpec\": {\n",
    "                \"name\": \"get_current_weather\",\n",
    "                \"description\": \"Get the current weather in a given location\",\n",
    "                \"inputSchema\": {\n",
    "                    \"json\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"location\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                            },\n",
    "                            \"unit\": {\n",
    "                                \"type\": \"string\", \n",
    "                                \"enum\": [\"celsius\", \"fahrenheit\"]\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"location\"\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": \"How's the weather in Tokyo today?\"}],\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.converse(\n",
    "    modelId=\"apac.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    messages=messages,\n",
    "    toolConfig=tool_config\n",
    ")\n",
    "\n",
    "print(json.dumps(response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response['output']['message']\n",
    "messages.append(response_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {\n",
    "    \"get_current_weather\": get_current_weather,\n",
    "}\n",
    "\n",
    "# 使いたい関数は複数あるかもしれないのでループ\n",
    "for tool_request in response['output']['message']['content']:\n",
    "    # 関数を実行\n",
    "    function_name = tool_request['toolUse']['name']\n",
    "    function_to_call = available_functions[function_name]\n",
    "    function_args = tool_request['toolUse']['input']\n",
    "    function_response = json.loads(\n",
    "        function_to_call(\n",
    "            location=function_args.get(\"location\"),\n",
    "            unit=function_args.get(\"unit\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(function_response)\n",
    "\n",
    "    # 関数の実行結果を会話履歴としてmessagesに追加\n",
    "    messages.append(\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"toolResult\": \n",
    "                        {\n",
    "                            \"toolUseId\": tool_request['toolUse']['toolUseId'],\n",
    "                            \"content\": [{\"json\": function_response}]\n",
    "                        }\n",
    "\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(messages, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_response = client.converse(\n",
    "    modelId=\"apac.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    messages=messages,\n",
    "    toolConfig=tool_config\n",
    ")\n",
    "output_message = response['output']['message']\n",
    "\n",
    "print(json.dumps(second_response, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
